{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2717ad6",
   "metadata": {},
   "source": [
    "#  Regridding MAIAC data for GEOS-Chem\n",
    "\n",
    "In this Jupyter Notebook we provide the process for generating a regridded version of processed MAIAC data to fit our needs for GEOS-Chem. The original data in question is fitted for a 0.05° granularity (already transformed from a sinusoidal grid, individual band data handling and quality check processed), while the GEOS-Chem grid is using 0.25° (lat) by 0.3125° (lon) cells. For our use case, we are simply concerned with a rectangular region centered over India (from 0° to 40° N and 55.9375° E to 106.5° E), for the year 2015.  Thus, we need to consolidate the contents of the original grid using a regridding process. In addition, we provide necessary code to visualize the original data and regridded data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669338e4",
   "metadata": {},
   "source": [
    "This cell simply makes all the required imports to have the necessary libraries. Beyond default Python libraries,\n",
    "we will be using PyHDF and NetCDF4 for processing the input HDF4 data and outputting to NetCDF, as well as NumPy\n",
    "for general data manipulation. Matplotlib and Cartopy are for the visualization process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyhdf.SD import SD, SDC\n",
    "import numpy as np\n",
    "import math\n",
    "from netCDF4 import Dataset \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fbae7",
   "metadata": {},
   "source": [
    "Here, we download the data from the site to our local storage using the CURL utility. Each file should be 311.045622 MB, so you may need to re-run this for select files if the file size does not appear as such - or if the file has errors when trying to open (uncomment the code in the middle to deal with this). Change the variable LOCAL to be the path to where you wish to store the data, and the day_start, day_end and year as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL = \"/data0/rm3873/regrid_data_005/\"\n",
    "day_start = 1\n",
    "day_end = 366\n",
    "year = 2015\n",
    "expected_size_mb = 311.045622\n",
    "redownload_mode = False\n",
    "\n",
    "s1 = \"https://portal.nccs.nasa.gov/datashare/maiac/DataRelease/CMG_0.05degree/AOT5km/2015/MAIACCMG.2015\"\n",
    "s3 = \".hdf\"\n",
    "\n",
    "for i in range(day_start,day_end):\n",
    "    outname = LOCAL + str(year) + \"_\" + str(i) + \".hdf\"\n",
    "    \n",
    "    #Uncomment this section if you are running through your downloaded files and checking they are the right size.\n",
    "    '''\n",
    "    redownload_mode = True\n",
    "    size = os.path.getsize(outname)/1000000.0\n",
    "    print(str(size) + \" MB\")\n",
    "    if(size != expected_size_mb):\n",
    "        print(\"Re-downloading needed\")\n",
    "    else:\n",
    "        continue\n",
    "    '''\n",
    "    progress_str = \"Downloading Day \" + str(i) \" of \" + str(day_end - day_start)\n",
    "    if(redownload_mode):\n",
    "        progress_str = \"Re-downloading Day \" + str(i)\n",
    "        \n",
    "    print(progress_str)      \n",
    "    s2 = str(i)\n",
    "    if(i < 10):\n",
    "        s2 = \"00\" + str(i)\n",
    "    if(i >= 10 and i < 100):\n",
    "        s2 = \"0\" + str(i)\n",
    "    link = s1+s2+s3\n",
    "    \n",
    "    cmd = \"curl -o \" + outname + \" \" + link\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89c43d",
   "metadata": {},
   "source": [
    "Adjust the desired path for the output of the regridding process, both regular and binary \n",
    "(0 for missing values, 1 for present values), and sent regular_mode to False if you are doing the\n",
    "binary process. You can adjust the lat/lon values and grid size as well, for the region and target grid size \n",
    "you want (assuming a lat-long grid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5635d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_path = '/data0/rm3873/binary_regridded.nc'\n",
    "regular_path = '/data0/rm3873/regridded.nc'\n",
    "regular_mode = True\n",
    "lat_st = 0\n",
    "lat_end = 40.25\n",
    "lat_siz = 0.25\n",
    "lon_st = 55.9375\n",
    "lon_end = 106.5\n",
    "lon_siz = 0.3125"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f78de7",
   "metadata": {},
   "source": [
    "This cell sets up the output NetCDF file. We create variables for the latitude, longitude\n",
    "to fit our target region, as well as the time, simply representing each day of the year. We\n",
    "then have our 3D array to represent the regridded data, 1 lat-long grid for each day of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncfile = Dataset(regular_path,mode='w',format='NETCDF4_CLASSIC') \n",
    "if(not regular_mode):\n",
    "    ncfile = Dataset(binary_path,mode='w',format='NETCDF4_CLASSIC') \n",
    "lat_dim = ncfile.createDimension('lat', 161)     \n",
    "lon_dim = ncfile.createDimension('lon', 162)\n",
    "time = ncfile.createDimension('time',day_end-day_start)\n",
    "\n",
    "lat = ncfile.createVariable('lat', np.float32, ('lat',))\n",
    "lat.units = 'degrees_north'\n",
    "lat.long_name = 'latitude'\n",
    "lon = ncfile.createVariable('lon', np.float32, ('lon',))\n",
    "lon.units = 'degrees_east'\n",
    "lon.long_name = 'longitude'\n",
    "time = ncfile.createVariable('time', np.float64, ('time',))\n",
    "time.units = 'days of 2015'\n",
    "time.long_name = 'days_of_the_year'\n",
    "# Define a 3D variable to hold the data\n",
    "aot = ncfile.createVariable('aot',np.float64,('time','lat','lon')) # note: unlimited dimension is leftmost\n",
    "\n",
    "lat[:] = np.arange(lat_st,lat_end,lat_siz)\n",
    "lon[:] = np.arange(lon_st,lon_end,lon_siz)\n",
    "time[:] = np.arange(day_start,day_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c39ba1",
   "metadata": {},
   "source": [
    "This cell contains the meat of the actual regridding process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6906b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regridded = np.full((day_end-day_start,161,162), -0.1)\n",
    "for day in range(day_start,day_end):\n",
    "    print('Day: ' + str(day))\n",
    "    fname = LOCAL + str(year) + \"_\" + str(day) + \".hdf\"\n",
    "    f = SD(fname, SDC.READ)\n",
    "    sel = f.select('AOT').get()\n",
    "    MISSING = -28672\n",
    "    data = np.full((3600,7200), MISSING)\n",
    "    for m in range(3600):\n",
    "        for n in range(7200):\n",
    "            data[m][n] = sel[m][n]\n",
    "    i=1000\n",
    "    ct_lat = 0\n",
    "    lat_str = 5\n",
    "    threshold = 0.5\n",
    "\n",
    "\n",
    "    while(i < 1800):\n",
    "        #print(str((i-1000)/800*100) + '% complete!')\n",
    "        if(ct_lat == 159):\n",
    "            lat_str = 3\n",
    "        if(ct_lat == 160):\n",
    "            lat_str = 2\n",
    "        j = 4718\n",
    "        ct_lon = 0\n",
    "        lon_str = 6\n",
    "        while(j < 5725):\n",
    "            if(ct_lon == 155):\n",
    "                lon_str = 11\n",
    "\n",
    "            #print('Bounding box: [' + str(i) + ',' + str(i+lat_str) + ' by ' + str(j) + ',' + str(j+lon_str) + '] for idx (' + str(ct_lat) + ',' + str(ct_lon) + ')')\n",
    "            cur_row = [m for m in range(i,i+lat_str)] \n",
    "            cur_col = [n for n in range(j,j+lon_str)]\n",
    "            cur_box_idx = np.ix_(cur_row,cur_col)\n",
    "            cur_box = data[cur_box_idx]\n",
    "\n",
    "            total_ct = len(cur_box) * len(cur_box[0])\n",
    "            non_miss = []\n",
    "            for a in range(len(cur_box)):\n",
    "                for b in range(len(cur_box[a])):\n",
    "                    if(cur_box[a][b] != MISSING):\n",
    "                        non_miss.append(cur_box[a][b]* 0.001)\n",
    "\n",
    "\n",
    "            cur_val =  -0.1\n",
    "            if(not regular_mode):\n",
    "                cur_val = 0\n",
    "            if(len(non_miss) >= threshold * total_ct):\n",
    "                non_miss = np.array(non_miss)\n",
    "                cur_val = np.average(non_miss)\n",
    "                if(not regular_mode):\n",
    "                    cur_val = 1\n",
    "\n",
    "            regridded[day - 1][ct_lat][ct_lon] = cur_val\n",
    "            ct_lon = ct_lon + 1\n",
    "            j = j + lon_str\n",
    "\n",
    "\n",
    "        ct_lat = ct_lat + 1\n",
    "        i = i + lat_str\n",
    "aot[::] = regridded\n",
    "ncfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e71f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 28\n",
    "fname = \"/data0/rm3873/regrid_data_005/2015_\" + str(day) + \".hdf\"\n",
    "f = SD(fname, SDC.READ)\n",
    "sel = f.select('AOT').get()\n",
    "MISSING = -28672\n",
    "\n",
    "#lons = np.full((1681-1080,5586-4960),-0.1)\n",
    "#lats = np.full((1681-1080,5586-4960),-0.1)\n",
    "#vals = np.full((1681-1080,5586-4960),-0.1)\n",
    "lons = []\n",
    "lats = []\n",
    "vals = []\n",
    "lats_miss = []\n",
    "lons_miss = []\n",
    "\n",
    "for i in range(1080,1681):\n",
    "    if(i % 50 == 0):\n",
    "        print(i)\n",
    "    for j in range(4960,5586):\n",
    "        lat = 90 - i*0.05\n",
    "        lon = j*0.05 - 180\n",
    "        if(sel[i][j] != MISSING):\n",
    "            sel[i][j] = sel[i][j] * 0.001\n",
    "            #vals[i-1080][j-4960] = sel[i][j]\n",
    "            vals.append(sel[i][j])\n",
    "            lats.append(lat)\n",
    "            lons.append(lon)\n",
    "        else:\n",
    "            lats_miss.append(lat)\n",
    "            lons_miss.append(lon)\n",
    "        #lats[i-1080][j-4960] = lat\n",
    "        #lons[i-1080][j-4960] = lon\n",
    "        \n",
    "plt.figure(figsize=(16,16),facecolor='white', dpi=80)\n",
    "ax = plt.axes(projection=ccrs.Mercator(min_latitude=5,max_latitude=40,central_longitude=84))\n",
    "ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,linewidth=2, color='gray', alpha=0.5, linestyle='--')\n",
    "ax.set_extent([67,100,5,37])\n",
    "ax.add_feature(cartopy.feature.LAND)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "ax.add_feature(cartopy.feature.COASTLINE,linewidth=0.4)\n",
    "ax.add_feature(cartopy.feature.BORDERS, linestyle=':',linewidth=0.4)\n",
    "plt.scatter(x=lons,y=lats,c=vals, cmap='viridis',s=4,alpha=1,transform=ccrs.PlateCarree())\n",
    "cb = plt.colorbar(label=\"AOT\")\n",
    "plt.scatter(x=lons_miss,y=lats_miss,c='white',s=4,alpha=1,transform=ccrs.PlateCarree())\n",
    "plt.text(0,0,\"White points are missing values\", fontsize=20,bbox=dict(facecolor='red', alpha=1))\n",
    "plt.savefig(\"raw_data_viz.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed66f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MISSING = -0.1\n",
    "\n",
    "lons = []\n",
    "lats = []\n",
    "vals = []\n",
    "lats_miss = []\n",
    "lons_miss = []\n",
    "\n",
    "for i in range(161):\n",
    "    if(i % 10 == 0):\n",
    "        print(i)\n",
    "    for j in range(162):\n",
    "        lat = i*0.25\n",
    "        lon = j*0.3125 + 56.25\n",
    "        if(regridded[i][j] != MISSING):\n",
    "            vals.append(regridded[i][j])\n",
    "            lats.append(lat)\n",
    "            lons.append(lon)\n",
    "        else:\n",
    "            lats_miss.append(lat)\n",
    "            lons_miss.append(lon)\n",
    "            \n",
    "plt.figure(figsize=(16,16),facecolor='white', dpi=80)\n",
    "ax = plt.axes(projection=ccrs.Mercator(min_latitude=5,max_latitude=40,central_longitude=84))\n",
    "ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,linewidth=2, color='gray', alpha=0.5, linestyle='--')\n",
    "ax.set_extent([67,100,5,37])\n",
    "ax.add_feature(cartopy.feature.LAND)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "ax.add_feature(cartopy.feature.COASTLINE,linewidth=0.4)\n",
    "ax.add_feature(cartopy.feature.BORDERS, linestyle=':',linewidth=0.4)\n",
    "plt.scatter(x=lons,y=lats,c=vals, cmap='cool',s=4,alpha=1,transform=ccrs.PlateCarree())\n",
    "cb = plt.colorbar(label=\"AOT\")\n",
    "plt.scatter(x=lons_miss,y=lats_miss,c='gray',s=4,alpha=1,transform=ccrs.PlateCarree())\n",
    "plt.text(0,0,\"Gray points are missing values\", fontsize=20,bbox=dict(facecolor='red', alpha=1))\n",
    "plt.savefig(\"raw_data_viz_regridded.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
